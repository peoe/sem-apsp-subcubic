\chapter{Problem Setting}

\section{Finding Shortest Paths}

Throughout this manuscript we assume $G = (V, E, \omega)$ to be a directed weighted graph.
In particular we make use of the notations of
\begin{itemize}
    \item a set of \emph{vertices} $V \subseteq \bb{Z}$,
    \item a set of \emph{edges} $E \subseteq \power{V}$, and
    \item a \emph{weight mapping} $\omega \in E' = \ISET{\varphi: E \rightarrow \bb{R}}{$\varphi$ linear}$.
\end{itemize}
In combining multiple edges we define a path $p \in \fk{P}(G)$ to be a tuple of edges $(e_1, e_2, \dots, e_n)$ such that each subsequent pair of edges within the path are connected within the graph.
This can be expressed through the condition $\forall i = 1, \dots, n - 1: e_i^{(2)} = e_{i + 1}^{(1)}$, where $e^{(1)}$ denotes the starting vertex and $e^{(2)}$ signifies the end vertex of the edge $e$.
By identifying each edge with its two constituent vertices and keeping track of the number of total elements in the tuple we can equivalently write $p = (e_1, e_2, \dots, e_n) = (v_1, \dots, v_{n + 1})$, where $e_i = (v_i, v_{i + 1})$.
For ease of notation we further denote the subset of all paths from a vertex $u \in V$ to a vertex $v \in V$ by
\[
    \fk{P}(G; u, v) \coloneqq \ISET{p \in \fk{P}(G)}{$p$ starts in $u$ and ends in $v$} \subseteq \fk{P}(G).
\]
For vertices $u, v, w \in V$ and related paths $p_1 = {(u_i)}_{i = 1}^n \in \fk{P}(G; u, v), p_2 = {(v_j)}_{j = 1}^m \in \fk{P}(G; v, w)$ we further define the \emph{concatenation}
\[
    p_1 \oplus p_2 \coloneqq (u_1, u_2, \dots, u_n = v_1, v_2, \dots, v_m).
\]

In applications of graph theory one often wants to find paths in a graph that satisfy certain properties.
Our quantity of interest will be the \emph{weight} any path $p \in \fk{P}(G)$ on a weighted graph $G$ defined by
\[
    \omega(p) \coloneqq \omega\left( e_1 + e_2 + \cdots + e_n \right) = \sum\limits_{i = 1}^n \omega(e_i),
\]
where we applied the linearity of $\omega$ in the equality.
In particular, we will try to find those paths which obtain the minimum weight possible between two vertices.
These so-called \emph{shortest paths} are defined as
\[
    \SP_G(u, v) \coloneqq p^* = \argmin\limits_{p \in \fk{P}(G; u, v)} \omega(p).
\]

In general, the existence and uniqueness of a shortest path cannot be guaranteed.
One example where the existence can never be satisfied is a graph with two connected components $V_1, V_2$.
Taking any nodes $u \in V_1, v \in V_2$, one can never find a path from $u$ to $v$, and vice versa.
Such unconnected graphs can be dealt with by choosing an appropriate initialization in the shortest path finding algorithms.
This, in practice, this never causes any problems.
Much more problematic is the existence of \emph{negative weight cycles}, that is a path $c = (v_1, v_2, \dots, v_n), v_1 = v_n = a, a \in V$, with weight $\omega(c) < 0$.
Suppose that for two vertices $u, v \in V$ the vertex $a$ from the negative weight cycle $c$ were reachable on a path $p = (u_1, u_2, \dots, u_{j - 1}, a, u_{j + 1}, \dots, u_n), u_1 = u, u_n = v$, for some $j \in \sset{1, \dots, n}$.
Decomposing $p = (u_1, u_2, \dots, u_{j - 1}, a) \oplus (a, u_{j + 1}, \dots, u_n) \eqqcolon p_1 \oplus p_2$, we can now compute
\[
    \omega(p) = \omega(p_1) + \omega(p_2) > \omega(p_1) + \underbrace{\omega(c)}_{< 0} + \omega(p_2) = \omega(p_1 \oplus c \oplus p_2) > \omega(p_1) + \sum\limits_{i = 1}^\infty \omega(c) + \omega(p_2) = -\infty.
\]
Hence, by repeatedly traversing the negative weight cycle $c$ after reaching vertex $a$ we can decrease the total weight of the path from $u$ to $v$ to an arbitrarily small number.
By this construction, there can be no shortest path from $u$ to $v$ although there clearly exists a path $p \in \fk{P}(G; u, v)$.
Concluding from this remark, we explicitly assume that our graph contains no negative weight cycles.
This in fact does not prove a constraint on our weight function $\omega$ to only map to $\bb{R}_{\ge 0}$, but rather an abstract bound on the graphs we are about to consider further.

\section{Single Source Shortest Paths Problems}

With the elementary definition of a shortest path in hand we can now consider the general set of shortest paths problems, cf.~\cite[Chapter~24]{Cormen2001}.
The obvious question is the number of degrees of freedom we consider when computing shortest paths.
Instead of directly considering all possible vertex pairs $(u, v) \in V \times V$, we first reduce the problem of finding shortest paths to the following two cases:
\begin{itemize}
    \item Fixing the vertex at the start of the shortest path, we can get the class of so-called \emph{Single Source Shortest Paths Problems} (SSSPPs).
    \item Choosing instead a fixed vertex as the target of the shortest path, we obtain \emph{Single Destination Shortest Paths Problems} (SDSPPs).
\end{itemize}
The connection to the more general problem is immediate and will be covered in more detail in the next section.
Inherently, SSSPPs and SDSPPs both consider two similar subproblems, albeit from differing ends of the path.
Here we will only consider SSSPPs in further detail, but analogous approaches can be taken to solve SDSPPs.

\begin{definition}[Single Source Shortest Paths Problem]\label{def:ssspps}
    Let $u \in V$ be fixed. Then the Single Source Shortest Paths Problem on a graph $G$ can be stated as
    \begin{displayquote}
        ``For all $v \in V$ find a shortest path $p = \SP_G(u, v)$ and its associated weight $\omega(p)$.''
    \end{displayquote}
\end{definition}

At this point we have to pay our dues by explaining how we handle vertices for which no shortest path exists.
Algorithmically, we can always initialize the weight of the current shortest path to $\infty$, or a very large value in practice.
Thus, if no shortest path exists between any two vertices, we have a safe fallback value for the weight of the shortest path.
Representatively, one can imagine a vector of real numbers storing the weights of the current estimate of the weight of the shortest paths from our starting vertex to every possible target vertex in the graph indexed by some ordering on the set of vertices.
We note that the ordering of the vertices can be seen in our description of $V \subseteq \bb{Z}$ by indexing the vertices in accordance to the number representing them.

Solving SSSPPs in an algorithmic manner will always require an update by a so-called \emph{relaxation step}.
In this update step the algorithm compares the weights of paths from the starting vertex through an intermediate vertex to the target vertex and then updates the underlying weight vector accordingly.
This step corresponds to checking if a path with a lower weight is possible by taking a detour through another vertex.
Figure~\ref{alg:relaxation} shows the relaxation in pseudocode for one edge; note that the source vertex is not explicitly mentioned, but instead implicitly given by the weight vector $w$.

\begin{figure}[ht]
    \centering
    \begin{minipage}{.4\textwidth}
        \begin{algorithm}[H]
            \SetKwProg{Def}{def}{:}{}
            \KwData{
                Edge $e = (u, v)$, \\
                estimated weight vector $w$
            }
            \Def{relax$(u, v, w)$}{
                \If{$w(v) > w(u) + \omega(e)$}{
                    $w(v) \coloneqq w(u) + \omega(e)$\;
                }
            }
        \end{algorithm}
    \end{minipage}
    \caption{Relaxation step, adapted from~\cite[Chapter~24]{Cormen2001}}\label{alg:relaxation}
\end{figure}

This relaxation can now be used in the \emph{Bellman-Ford algorithm}, of which a pseudocode version can be found in Figure~\ref{alg:bellman-ford}.
We progressively iterate over all vertices, and update the estimated weight vector with the relaxation step.
At every step within the algorithm the estimated weight vector gives an upper bound on the weight of the shortest path from a starting vertex $s \in V$.
The particular implementation here lacks a few features present in~\cite{Cormen2001}.
These features are mainly twofold: keeping track of preceding vertices and checking for negative weight cycles.
The former can be easily inserted into the relaxation step by keeping track of each vertices predecessor after a potential update; we omit this property here because the algorithm proposed by~\cite{Chan2007} uses a completely different mechanism which we will discuss in Section~\ref{sec:recovery}.
In contrast, the latter feature is rendered obsolete thanks to our assumption of the absence of any negative weight cycles from our graph.

\begin{figure}[ht]
    \centering
    \begin{minipage}{.4\textwidth}
        \begin{algorithm}[H]
            \KwData{
                Starting vertex $s \in V$, \\
                estimated weight vector $w$
            }
            \For{$i = 1, \dots, \abs{V} - 1$}{
                \ForEach{$e = (u, v) \in E$}{
                    $relax(u, v, w)$
                }
            }
        \end{algorithm}
    \end{minipage}
    \caption{Bellman-Ford algorithm, adapted from~\cite[Section~24.1]{Cormen2001}}\label{alg:bellman-ford}
\end{figure}

Following~\cite{Cormen2001}, we calculate the computational complexity of the Bellman-Ford algorithm to be $\mathcal{O}(\abs{V} \cdot \abs{E})$.
Bounding the number of graph vertices by a number $n \in \bb{N}$, we can further simplify the complexity to $\mathcal{O}(\abs{V} \cdot \abs{E}) = \mathcal{O}\left( n^3 \right)$.
When considering more general shortest pairs problems with a naive approach derived from Bellman-Ford we will see that this complexity can be drastically improved.

\section{All Pairs Shortest Paths Problems}

Instead of fixing any degrees of freedom for the start or the target vertices we can consider both to be arbitrarily chosen from $V$.
This transforms the SSSPPs, and the SDSPPs respectively, into \emph{All Pairs Shortest Paths Problems} (APSPPs).

\begin{definition}[All Pairs Shortest Paths Problem]
    The All Pairs Shortest Paths Problem on a graph $G$ can be stated as
    \begin{displayquote}
        ``For all pairs $(u, v) \in V \times V$ find a shortest path $p = \SP_G(u, v)$ and its weight $\omega(p)$.''
    \end{displayquote}
\end{definition}

If we consider APSPPs as plain generalizations of SSSPPs in the sense that we just solve an SSSPP for every starting vertex $u \in V$, we get an immediate solution to the overarching APSPP in Figure~\ref{alg:bellman-ford-apsp}.
Computing the runtime for a graph with $\abs{V} = n \in \bb{N}$ we get $\mathcal{O}\left( n \cdot n^3 \right) = \mathcal{O}\left( n^4 \right)$.
There are multiple well known improvements to be made to this algorithm.
The first is related to graph structure and its algebraic representation through matrix multiplication yielding $\mathcal{O}\left( n^3 \log(n) \right)$.
This approach exploits efficient matrix multiplication by application of appropriate matrix products and algebraic properties.
However, we want to deal with the matrix-graph relation later on in Section~\ref{sec:dist-prod} to make a straightforward connection to the method proposed by~\cite{Chan2007}.
Another improvement can be made by using the \emph{Floyd-Warshall algorithm}.
That algorithm will be discussed in the remainder of this chapter.

\begin{figure}[ht]
    \centering
    \begin{minipage}{.5\textwidth}
        \begin{algorithm}[H]
            \KwData{Estimated weight vectors ${(w_v)}_{v \in V}$}
            \ForEach{$s \in V$}{
                \For{$i = 1, \dots, \abs{V} - 1$}{
                    \ForEach{$e = (u, v) \in E$}{
                        $relax(u, v, w_s)$
                    }
                }
            }
        \end{algorithm}
    \end{minipage}
    \caption{Solving APSPPs using the Bellman-Ford algorithm}\label{alg:bellman-ford-apsp}
\end{figure}

The Floyd-Warshall algorithm in Figure~\ref{alg:floyd-warshall} operates directly on matrices.
These matrices again consist of upper bounds on the weights of shortest paths.
Connecting the set of vectors ${(w_v)}_{v \in V}$ in Figure~\ref{alg:bellman-ford-apsp} to a matrix is straightforward by indexing the vertices according to their superset $V \subseteq \bb{Z}$.
For convenience sake we assume that all vertices are numbered using $1, 2, \dots, n$, that is instead of considering $V \subseteq \bb{Z}$ we instead consider them to be represented by consecutive natural numbers.
We thus obtain a weight matrix $W \coloneqq {(w_{i, j})}_{i, j = 1}^{n, n}$.

Initializing this weight matrix before the first iteration is apparent by the direct edges originating from every vertex, and the convention that a shortest path from $u \in V$ to itself incurs a weight of $0$.
Observing the reasonability of this convention is immediate: Assuming the existence of a path $p = (u, u_1, u_2, \dots, u_n, u)$ with $\omega(p) < 0$, we notice that $p$ is a negative weight cycle and hence such a path cannot exist within our graph.
The other matrix entries are initialized in the following manner:
\[
    w_{i, j} \coloneqq \begin{cases}
        \omega(e), & e = (i, j) \in E \\
        \infty, & e = (i, j) \not\in E.
    \end{cases}
\]

To be able to recover shortest paths after runtime,\ \cite[Chapter~25]{Cormen2001} proposes to create a new weight matrix for every iteration.
We will omit this additional notation here, because path recovery in~\cite{Chan2007} uses a completely different mechanism, as previously mentioned.
This causes no problems with the algorithm, cf.~\cite[Exercise~25.4-5]{Cormen2001}.

\begin{figure}[ht]
    \centering
    \begin{minipage}{.6\textwidth}
        \begin{algorithm}[H]
            \KwData{Estimated weight matrix $W = {(w_{i, j})}_{i, j = 1}^{n, n}$}
            \For{$k = 1, \dots, n$}{
                \For{$i = 1, \dots, n$}{
                    \For{$j = 1, \dots, n$}{
                        $w_{i, j} \coloneqq \min(w_{i, j}, w_{i, k} + w_{k, j})$
                    }
                }
            }
        \end{algorithm}
    \end{minipage}
    \caption{Floyd-Warshall algorithm, adapted from~\cite[Chapter~25]{Cormen2001}}\label{alg:floyd-warshall}
\end{figure}

To further highlight the connection to the previous approach we take a look at the update of the weights in Figure~\ref{alg:floyd-warshall}.
When compared to the relaxation comparison in Figure~\ref{alg:relaxation} there is a striking similarity representing the the check for a shorter path via an other intermediate vertex.
This relation will be preserved when we have a look at the approach described in~\cite{Chan2007} because it is essential to all shortest paths problems.
In particular, fast evaluation of this expression will play a considerable role when considering different arguments.

The complexity now amounts to $\mathcal{O}\left( n^3 \right)$ because we just need to consider three \textbf{\texttt{for}} loops over $n$ elements each.
This is much better than the naive $\mathcal{O}\left( n^4 \right)$, or even the improved $\mathcal{O}\left( n^3 \log(n) \right)$, but still separated by the result from~\cite{Chan2007} by another logarithmic factor.
What change in methodology might yield this illusive logarithmic factor\textinterrobang{}
